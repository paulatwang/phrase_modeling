{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phrase Modelling Part III - Analyzing the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gensim import corpora, models, utils\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd() + '/tmp/'\n",
    "\n",
    "sanctity_dict = corpora.Dictionary.load(path + 'sanctity_dict.dict')\n",
    "degradation_dict = corpora.Dictionary.load(path + 'degradation_dict.dict')\n",
    "fairness_dict = corpora.Dictionary.load(path + 'fairness_dict.dict')\n",
    "cheating_dict = corpora.Dictionary.load(path + 'cheating_dict.dict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd() + '/tmp/'\n",
    "\n",
    "sanctity_corpus = corpora.MmCorpus(path + 'sanctity_corpus.mm')\n",
    "degradation_corpus = corpora.MmCorpus(path + 'degradation_corpus.mm')\n",
    "fairness_corpus = corpora.MmCorpus(path + 'fairness_corpus.mm')\n",
    "cheating_corpus = corpora.MmCorpus(path + 'cheating_corpus.mm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd() + '/tmp/'\n",
    "\n",
    "sanctity_lda = models.ldamodel.LdaModel.load(path + 'sanctity_lda_model')\n",
    "degradation_lda = models.ldamodel.LdaModel.load(path + 'degradation_lda_model')\n",
    "fairness_lda = models.ldamodel.LdaModel.load(path + 'fairness_lda_model')\n",
    "cheating_lda = models.ldamodel.LdaModel.load(path + 'cheating_lda_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.026*\"cases\" + 0.014*\"covid\" + 0.009*\"black\" + 0.008*\"plans\" + '\n",
      "  '0.008*\"best\" + 0.008*\"coronavirus\" + 0.008*\"man\" + 0.006*\"iran\" + '\n",
      "  '0.006*\"democrats\" + 0.006*\"supreme_court\"'),\n",
      " (1,\n",
      "  '0.016*\"police\" + 0.012*\"oil\" + 0.011*\"coronavirus\" + 0.010*\"uk\" + '\n",
      "  '0.010*\"stock\" + 0.009*\"market\" + 0.008*\"update\" + 0.007*\"hit\" + '\n",
      "  '0.007*\"covid\" + 0.007*\"quarter\"'),\n",
      " (2,\n",
      "  '0.021*\"china\" + 0.021*\"virus\" + 0.014*\"coronavirus\" + 0.013*\"amid\" + '\n",
      "  '0.013*\"stocks\" + 0.012*\"million\" + 0.010*\"deal\" + 0.009*\"global\" + '\n",
      "  '0.009*\"surge\" + 0.008*\"eu\"'),\n",
      " (3,\n",
      "  '0.029*\"new\" + 0.026*\"trump\" + 0.024*\"says\" + 0.017*\"coronavirus\" + '\n",
      "  '0.008*\"covid\" + 0.007*\"state\" + 0.006*\"report\" + 0.005*\"billion\" + '\n",
      "  '0.005*\"india\" + 0.005*\"pandemic\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint(degradation_lda.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 1991.9742341041565 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "def format_topics_sentences(ldamodel, corpus, texts):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "        # print(row)\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(sanctity_lda, sanctity_corpus, sanctity_dict)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "df_dominant_topic.head(10)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Elapsed:\", end - start, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3091</td>\n",
       "      <td>china, pandemic, coronavirus, amid, covid, time, global, million, stock, people</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3068</td>\n",
       "      <td>china, pandemic, coronavirus, amid, covid, time, global, million, stock, people</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3038</td>\n",
       "      <td>china, pandemic, coronavirus, amid, covid, time, global, million, stock, people</td>\n",
       "      <td>baghdadi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3062</td>\n",
       "      <td>china, pandemic, coronavirus, amid, covid, time, global, million, stock, people</td>\n",
       "      <td>death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3062</td>\n",
       "      <td>china, pandemic, coronavirus, amid, covid, time, global, million, stock, people</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3078</td>\n",
       "      <td>china, pandemic, coronavirus, amid, covid, time, global, million, stock, people</td>\n",
       "      <td>mining</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3110</td>\n",
       "      <td>china, pandemic, coronavirus, amid, covid, time, global, million, stock, people</td>\n",
       "      <td>nevada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3093</td>\n",
       "      <td>china, pandemic, coronavirus, amid, covid, time, global, million, stock, people</td>\n",
       "      <td>protect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3103</td>\n",
       "      <td>china, pandemic, coronavirus, amid, covid, time, global, million, stock, people</td>\n",
       "      <td>rare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3062</td>\n",
       "      <td>china, pandemic, coronavirus, amid, covid, time, global, million, stock, people</td>\n",
       "      <td>seeks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0             0             3.0              0.3091   \n",
       "1             1             3.0              0.3068   \n",
       "2             2             3.0              0.3038   \n",
       "3             3             3.0              0.3062   \n",
       "4             4             3.0              0.3062   \n",
       "..          ...             ...                 ...   \n",
       "95           95             3.0              0.3078   \n",
       "96           96             3.0              0.3110   \n",
       "97           97             3.0              0.3093   \n",
       "98           98             3.0              0.3103   \n",
       "99           99             3.0              0.3062   \n",
       "\n",
       "                                                                           Keywords  \\\n",
       "0   china, pandemic, coronavirus, amid, covid, time, global, million, stock, people   \n",
       "1   china, pandemic, coronavirus, amid, covid, time, global, million, stock, people   \n",
       "2   china, pandemic, coronavirus, amid, covid, time, global, million, stock, people   \n",
       "3   china, pandemic, coronavirus, amid, covid, time, global, million, stock, people   \n",
       "4   china, pandemic, coronavirus, amid, covid, time, global, million, stock, people   \n",
       "..                                                                              ...   \n",
       "95  china, pandemic, coronavirus, amid, covid, time, global, million, stock, people   \n",
       "96  china, pandemic, coronavirus, amid, covid, time, global, million, stock, people   \n",
       "97  china, pandemic, coronavirus, amid, covid, time, global, million, stock, people   \n",
       "98  china, pandemic, coronavirus, amid, covid, time, global, million, stock, people   \n",
       "99  china, pandemic, coronavirus, amid, covid, time, global, million, stock, people   \n",
       "\n",
       "        Text  \n",
       "0   american  \n",
       "1        bad  \n",
       "2   baghdadi  \n",
       "3      death  \n",
       "4       mean  \n",
       "..       ...  \n",
       "95    mining  \n",
       "96    nevada  \n",
       "97   protect  \n",
       "98      rare  \n",
       "99     seeks  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dominant_topic.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 0.08580493927001953 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Display setting to show more characters in column\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=False).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Representative Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head(10)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Elapsed:\", end - start, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Representative Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3275</td>\n",
       "      <td>china, pandemic, coronavirus, amid, covid, time, global, million, stock, people</td>\n",
       "      <td>reinterpret</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_Num  Topic_Perc_Contrib  \\\n",
       "0        3.0              0.3275   \n",
       "\n",
       "                                                                          Keywords  \\\n",
       "0  china, pandemic, coronavirus, amid, covid, time, global, million, stock, people   \n",
       "\n",
       "  Representative Text  \n",
       "0         reinterpret  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_topics_sorteddf_mallet.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
